{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install torch torchvision transformers rasa==1.7.0 input_reader","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nfrom sklearn import preprocessing\nimport ipywidgets as widgets\nimport requests, os\nfrom IPython.display import display\nfrom ipywidgets import interact\n\nfrom rasa.nlu.training_data import TrainingData,Message","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Download model\n\n#taken from this StackOverflow answer: https://stackoverflow.com/a/39225039\n\ndef download_file_from_google_drive(id, destination):\n    URL = \"https://docs.google.com/uc?export=download\"\n\n    session = requests.Session()\n\n    response = session.get(URL, params = { 'id' : id }, stream = True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { 'id' : id, 'confirm' : token }\n        response = session.get(URL, params = params, stream = True)\n\n    save_response_content(response, destination)    \n\ndef get_confirm_token(response):\n    for key, value in response.cookies.items():\n        if key.startswith('download_warning'):\n            return value\n\n    return None\n\ndef save_response_content(response, destination):\n    CHUNK_SIZE = 32768\n\n    with open(destination, \"wb\") as f:\n        for chunk in response.iter_content(CHUNK_SIZE):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)\n\nmodel_class_file_id = '1N1kn2b7i2ND7eNefzyJM-k13IM8tqZvr'\ncheckpoint_file_id = '1G0nwXlvzGsb8Ar-OAnYBQKFvY97WMzBy'\nmodel_class_destination = 'model.py'\ncheckpoint_destination = 'model.zip'\ncheckpoint_unzipped_destination = 'package_models'\n\nif not os.path.exists(checkpoint_unzipped_destination):\n    download_file_from_google_drive(checkpoint_file_id, checkpoint_destination)\n    !unzip {checkpoint_destination}\n\nif not os.path.exists(model_class_destination):\n    download_file_from_google_drive(model_class_file_id, model_class_destination)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from model import ParaphraseModel\nmodel_path = 'package_models/lm_finetune_8/checkpoint-56000/'\n\ncomplete_td = TrainingData()\nmodel = ParaphraseModel(model_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading our dataset\ntrain_df = pd.read_csv('../input/data-divide/reddit_data1.csv')\n\n# dropping rows having null values\ntrain_df.dropna(inplace=True)\n\n# creating a label column to encode our text labels to no.\nle = preprocessing.LabelEncoder()\nle.fit(train_df[\"flair\"])\ntrain_df[\"label\"] = le.transform(train_df[\"flair\"])\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict = {'text':[], \"label\":[]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ind, i in train_df.iterrows():\n    if (i[\"label\"] == 6) or (i[\"label\"] == 4):\n        text = model.get_paraphrases(i[\"dirty_text\"], 5, \"\")\n        result_dict[\"text\"].extend([text[1], i[\"dirty_text\"], text[4]])\n        result_dict[\"label\"].extend([i[\"label\"], i[\"label\"], i[\"label\"]])\n        \n    if i[\"label\"] == 1:\n        if np.random.random()<=0.84:\n            text = model.get_paraphrases(i[\"dirty_text\"], 5, \"\")\n            result_dict[\"text\"].extend([text[1],text[4]])\n            result_dict[\"label\"].extend([i[\"label\"], i[\"label\"], i[\"label\"]])\n        result_dict[\"text\"].append(i[\"dirty_text\"])\n        \n    if i[\"label\"] == 2:\n        if np.random.random()<=0.6:\n            text = model.get_paraphrases(i[\"dirty_text\"], 5, \"\")\n            result_dict[\"text\"].extend([text[1]])\n            result_dict[\"label\"].extend([i[\"label\"], i[\"label\"]])\n        result_dict[\"text\"].append(i[\"dirty_text\"])\n    \n    if i[\"label\"] == 0:\n        if np.random.random()<=0.18:\n            text = model.get_paraphrases(i[\"dirty_text\"], 5, \"\")\n            result_dict[\"text\"].extend([text[1]])\n            result_dict[\"label\"].extend([i[\"label\"], i[\"label\"]])\n        result_dict[\"text\"].append(i[\"dirty_text\"])\n            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame.from_dict(result_dict)\ndf.to_csv(\"augmented_data1.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}