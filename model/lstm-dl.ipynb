{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AskIndia' 'Business/Finance' 'Coronavirus' 'Non-Political'\n",
      " 'Policy/Economy' 'Politics' 'Science/Technology']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>flair</th>\n",
       "      <th>dirty_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top comments toi article drop us oil prices</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Top comments on a TOI article about the drop i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hacking networking security 2 books 1 hacking ...</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Hacking: Networking and Security (2 Books in 1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zakir khan irfan junejo live instagram session...</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Zakir Khan and Irfan Junejo live Instagram Ses...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cursing quentin tarantino movie</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Cursing In A Quentin Tarantino Movie</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          flair  \\\n",
       "0        top comments toi article drop us oil prices  Non-Political   \n",
       "1                                       disappointed       Politics   \n",
       "2  hacking networking security 2 books 1 hacking ...  Non-Political   \n",
       "3  zakir khan irfan junejo live instagram session...  Non-Political   \n",
       "4                    cursing quentin tarantino movie  Non-Political   \n",
       "\n",
       "                                          dirty_text  label  \n",
       "0  Top comments on a TOI article about the drop i...      3  \n",
       "1                                       Disappointed      5  \n",
       "2  Hacking: Networking and Security (2 Books in 1...      3  \n",
       "3  Zakir Khan and Irfan Junejo live Instagram Ses...      3  \n",
       "4               Cursing In A Quentin Tarantino Movie      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the csv and then removing rows with null balues\n",
    "train_df = pd.read_csv('../input/midas-task/reddit_data.csv')\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "# encoding text label to no. label\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_df[\"flair\"])\n",
    "train_df[\"label\"] = le.transform(train_df[\"flair\"])\n",
    "print(le.classes_)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a row for the no. of words in a text \n",
    "train_df['text_length'] = train_df['dirty_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising function for tokenization using spacy and preprocessing\n",
    "tok = spacy.load('en')\n",
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "counts = Counter()\n",
    "for index, row in train_df.iterrows():\n",
    "    counts.update(tokenize(row['dirty_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a vocabulary of words and creating a word to indez mapping\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to encode text using tokenization function created above and vocabulary\n",
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>flair</th>\n",
       "      <th>dirty_text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_length</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top comments toi article drop us oil prices</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Top comments on a TOI article about the drop i...</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[[15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hacking networking security 2 books 1 hacking ...</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Hacking: Networking and Security (2 Books in 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>[[16, 17, 18, 19, 20, 21, 22, 11, 21, 16, 23, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zakir khan irfan junejo live instagram session...</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Zakir Khan and Irfan Junejo live Instagram Ses...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>[[29, 30, 19, 31, 32, 33, 34, 35, 36, 37, 38, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cursing quentin tarantino movie</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Cursing In A Quentin Tarantino Movie</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[[39, 11, 5, 40, 41, 42, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          flair  \\\n",
       "0        top comments toi article drop us oil prices  Non-Political   \n",
       "1                                       disappointed       Politics   \n",
       "2  hacking networking security 2 books 1 hacking ...  Non-Political   \n",
       "3  zakir khan irfan junejo live instagram session...  Non-Political   \n",
       "4                    cursing quentin tarantino movie  Non-Political   \n",
       "\n",
       "                                          dirty_text  label  text_length  \\\n",
       "0  Top comments on a TOI article about the drop i...      3           13   \n",
       "1                                       Disappointed      5            1   \n",
       "2  Hacking: Networking and Security (2 Books in 1...      3           16   \n",
       "3  Zakir Khan and Irfan Junejo live Instagram Ses...      3           11   \n",
       "4               Cursing In A Quentin Tarantino Movie      3            6   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...  \n",
       "1  [[15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2  [[16, 17, 18, 19, 20, 21, 22, 11, 21, 16, 23, ...  \n",
       "3  [[29, 30, 19, 31, 32, 33, 34, 35, 36, 37, 38, ...  \n",
       "4  [[39, 11, 5, 40, 41, 42, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a column for the encoded text and encoding every row\n",
    "train_df['encoded'] = train_df['dirty_text'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the encoded text and label column and then splitting in trained and validation\n",
    "X = list(train_df['encoded'])\n",
    "y = list(train_df['label'])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising a class for PyTorch style dataset \n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and validation dataset\n",
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function for training\n",
    "def train_model(model, epochs=10, lr=0.001):\n",
    "    # extracting parameters for optimizer to update during training\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    # initialising optimizer\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        #shifting model to training mode\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            # passing values to model to get output\n",
    "            y_pred = model(x, l)\n",
    "            # initialising gradients data to zero\n",
    "            optimizer.zero_grad()\n",
    "            # shifting label to cuda beacuse predctions are also on cuda\n",
    "            y = y.cuda()\n",
    "            # calculating loss\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            # computing gradients\n",
    "            loss.backward()\n",
    "            # applying gradients\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "            # calculation metrics data like accuracies and loss\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        # printing after every 5 epochs\n",
    "        if i % 5 == 0:\n",
    "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "\n",
    "# creating function for validation          \n",
    "def validation_metrics (model, valid_dl):\n",
    "    #shiftinh model to evaluation mode, this will disable dropout like layers\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        y = y.cuda()\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred.cpu(), y.cpu().unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "vocab_size = len(words)\n",
    "# initialing dataloaders\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        text = text.cuda()\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        packed_embedded = pack_padded_sequence(embedded, text_lengths,batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model with the given values\n",
    "model = classifier(vocab_size, 100, 32, 7, 3, bidirectional = True, dropout = 0.1)\n",
    "# shifting model to cuda or GPU\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.776, val loss 1.759, val accuracy 0.295, and val rmse 2.701\n",
      "train loss 1.722, val loss 1.722, val accuracy 0.295, and val rmse 2.701\n",
      "train loss 1.696, val loss 1.711, val accuracy 0.295, and val rmse 2.701\n",
      "train loss 1.696, val loss 1.711, val accuracy 0.294, and val rmse 2.701\n",
      "train loss 1.692, val loss 1.708, val accuracy 0.295, and val rmse 2.700\n",
      "train loss 1.694, val loss 1.710, val accuracy 0.295, and val rmse 2.698\n",
      "train loss 1.693, val loss 1.707, val accuracy 0.296, and val rmse 2.696\n",
      "train loss 1.696, val loss 1.708, val accuracy 0.267, and val rmse 2.549\n"
     ]
    }
   ],
   "source": [
    "# Starting training\n",
    "train_model(model, epochs=40, lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# saving the trained lstm model  \n",
    "torch.save(model, \"reddit_lstm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
